{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f229c2be-42ff-44eb-9e06-d280a416232c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   CustomerID Lookalike1  Score1 Lookalike2  Score2 Lookalike3  Score3\n",
      "0       C0001      C0192  0.8521      C0184  0.8512      C0112  0.8428\n",
      "1       C0002      C0134  0.9573      C0106  0.9243      C0029  0.9107\n",
      "2       C0003      C0052  0.9864      C0031  0.9092      C0076  0.8411\n",
      "3       C0004      C0165  0.9724      C0155  0.9463      C0173  0.8984\n",
      "4       C0005      C0007  0.9097      C0112  0.8898      C0095  0.8242\n",
      "5       C0006      C0187  0.9007      C0168  0.8717      C0171  0.8195\n",
      "6       C0007      C0005  0.9097      C0120  0.8184      C0140  0.7979\n",
      "7       C0008      C0065  0.7617      C0084  0.7602      C0098  0.7584\n",
      "8       C0009      C0010  0.9205      C0062  0.8758      C0077  0.8681\n",
      "9       C0010      C0062  0.9519      C0009  0.9205      C0198  0.9139\n",
      "10      C0011      C0169  0.8969      C0153  0.8916      C0174  0.8702\n",
      "11      C0012      C0195  0.9264      C0136  0.8578      C0013  0.7861\n",
      "12      C0013      C0143  0.9146      C0022  0.8478      C0087  0.8404\n",
      "13      C0014      C0097  0.9250      C0151  0.9150      C0128  0.8842\n",
      "14      C0015      C0036  0.9202      C0123  0.8843      C0058  0.8400\n",
      "15      C0016      C0183  0.9992      C0067  0.8567      C0030  0.6895\n",
      "16      C0017      C0075  0.9283      C0090  0.8627      C0081  0.8484\n",
      "17      C0018      C0117  0.9641      C0046  0.8804      C0187  0.8029\n",
      "18      C0019      C0121  0.8699      C0161  0.7509      C0147  0.7134\n",
      "19      C0020      C0050  0.8620      C0140  0.8585      C0110  0.8320\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Load the datasets\n",
    "customers = pd.read_csv(\"Customers.csv\")\n",
    "products = pd.read_csv(\"Products.csv\")\n",
    "transactions = pd.read_csv(\"Transactions.csv\")\n",
    "\n",
    "# Merge datasets\n",
    "merged_data = transactions.merge(customers, on=\"CustomerID\", how=\"left\")\n",
    "merged_data = merged_data.merge(products, on=\"ProductID\", how=\"left\")\n",
    "\n",
    "# Feature Engineering\n",
    "# 1. Aggregate Transaction Data\n",
    "customer_features = merged_data.groupby(\"CustomerID\").agg(\n",
    "    total_spent=(\"TotalValue\", \"sum\"),\n",
    "    avg_transaction_value=(\"TotalValue\", \"mean\"),\n",
    "    total_transactions=(\"TransactionID\", \"nunique\"),\n",
    "    most_common_category=(\"Category\", lambda x: x.mode()[0] if not x.mode().empty else None)\n",
    ").reset_index()\n",
    "\n",
    "# 2. Merge Profile Data\n",
    "customer_profile = customers[[\"CustomerID\", \"Region\", \"SignupDate\"]]\n",
    "customer_features = customer_features.merge(customer_profile, on=\"CustomerID\", how=\"left\")\n",
    "\n",
    "# Handle Missing 'SignupDate' (if any)\n",
    "if customer_features[\"SignupDate\"].isnull().any():\n",
    "    print(\"Found missing values in 'SignupDate'. Filling them with a default date.\")\n",
    "    customer_features[\"SignupDate\"].fillna(\"2000-01-01\", inplace=True)\n",
    "\n",
    "# Convert 'SignupDate' to datetime and calculate 'days_since_signup'\n",
    "customer_features[\"SignupDate\"] = pd.to_datetime(customer_features[\"SignupDate\"])\n",
    "customer_features[\"days_since_signup\"] = (pd.Timestamp.now() - customer_features[\"SignupDate\"]).dt.days\n",
    "\n",
    "# Drop 'SignupDate' after extracting useful information\n",
    "customer_features = customer_features.drop(columns=[\"SignupDate\"])\n",
    "\n",
    "# One-Hot Encode 'Region' and 'most_common_category'\n",
    "encoder = OneHotEncoder()\n",
    "encoded_categories = encoder.fit_transform(customer_features[[\"most_common_category\"]]).toarray()\n",
    "encoded_category_df = pd.DataFrame(encoded_categories, columns=encoder.get_feature_names_out([\"most_common_category\"]))\n",
    "customer_features = pd.concat([customer_features.reset_index(drop=True), encoded_category_df], axis=1)\n",
    "customer_features = customer_features.drop(columns=[\"most_common_category\"])\n",
    "\n",
    "customer_features = pd.get_dummies(customer_features, columns=[\"Region\"], drop_first=True)\n",
    "\n",
    "# Normalize Numerical Features\n",
    "numerical_columns = [\"total_spent\", \"avg_transaction_value\", \"total_transactions\", \"days_since_signup\"]\n",
    "scaler = StandardScaler()\n",
    "customer_features[numerical_columns] = scaler.fit_transform(customer_features[numerical_columns])\n",
    "\n",
    "# Compute Similarity\n",
    "customer_ids = customer_features[\"CustomerID\"]\n",
    "features = customer_features.drop(columns=[\"CustomerID\"])\n",
    "similarity_matrix = cosine_similarity(features)\n",
    "\n",
    "# Generate Lookalike Recommendations\n",
    "lookalikes = {}\n",
    "for idx, customer_id in enumerate(customer_ids):\n",
    "    similarities = list(enumerate(similarity_matrix[idx]))\n",
    "    similarities = sorted(similarities, key=lambda x: x[1], reverse=True)[1:4]  # Top 3 similar customers\n",
    "    lookalikes[customer_id] = [(customer_ids[i], round(score, 4)) for i, score in similarities]\n",
    "\n",
    "# Create Lookalike.csv\n",
    "lookalike_data = []\n",
    "for customer_id, similar_customers in lookalikes.items():\n",
    "    row = [customer_id]\n",
    "    for similar_customer, score in similar_customers:\n",
    "        row.extend([similar_customer, score])\n",
    "    lookalike_data.append(row)\n",
    "\n",
    "lookalike_df = pd.DataFrame(\n",
    "    lookalike_data,\n",
    "    columns=[\"CustomerID\", \"Lookalike1\", \"Score1\", \"Lookalike2\", \"Score2\", \"Lookalike3\", \"Score3\"]\n",
    ")\n",
    "\n",
    "# Save the Lookalike.csv file\n",
    "lookalike_df = pd.read_csv(\"Lookalike.csv\")\n",
    "print(lookalike_df.head(20))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d5d9cae-2115-4785-aacf-3a72b2c68e46",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
